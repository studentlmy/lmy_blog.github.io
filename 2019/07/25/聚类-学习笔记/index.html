<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.ico?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16.ico?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="聚类——学习笔记​    这是一个关于聚类算法的学习笔记，在学习的过程中，参考学习了周志华老师的《机器学习》，李航老师的《统计学习方法》，邹博老师和唐宇迪老师的机器学习网课，以及网上的一些博客分享，其中李建平先生的博客中的分享和总结，给我提供了非常多的帮助。作为一个刚开始学习机器学习算法的学生，非常感谢网络上这些博主的总结和分享，也希望自己能够坚持下去，收获的同时给出自己的分享，做出一点点微薄的贡">
<meta name="keywords" content="机器学习,聚类,算法">
<meta property="og:type" content="article">
<meta property="og:title" content="聚类--学习笔记">
<meta property="og:url" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/index.html">
<meta property="og:site_name" content="Mengyu Liao Blog">
<meta property="og:description" content="聚类——学习笔记​    这是一个关于聚类算法的学习笔记，在学习的过程中，参考学习了周志华老师的《机器学习》，李航老师的《统计学习方法》，邹博老师和唐宇迪老师的机器学习网课，以及网上的一些博客分享，其中李建平先生的博客中的分享和总结，给我提供了非常多的帮助。作为一个刚开始学习机器学习算法的学生，非常感谢网络上这些博主的总结和分享，也希望自己能够坚持下去，收获的同时给出自己的分享，做出一点点微薄的贡">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563868681642.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563890382567.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563863833861.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563870386014.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563870438048.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563870492326.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563870532597.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1564066135661.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563957206834.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563970072445.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563970670788.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563972609072.png">
<meta property="og:image" content="https://img-blog.csdn.net/20160426002823787?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563884860873.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563885220041.png">
<meta property="og:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563882318053.png">
<meta property="og:updated_time" content="2019-07-25T15:43:41.962Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="聚类--学习笔记">
<meta name="twitter:description" content="聚类——学习笔记​    这是一个关于聚类算法的学习笔记，在学习的过程中，参考学习了周志华老师的《机器学习》，李航老师的《统计学习方法》，邹博老师和唐宇迪老师的机器学习网课，以及网上的一些博客分享，其中李建平先生的博客中的分享和总结，给我提供了非常多的帮助。作为一个刚开始学习机器学习算法的学生，非常感谢网络上这些博主的总结和分享，也希望自己能够坚持下去，收获的同时给出自己的分享，做出一点点微薄的贡">
<meta name="twitter:image" content="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/1563868681642.png">





  
  
  <link rel="canonical" href="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>聚类--学习笔记 | Mengyu Liao Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mengyu Liao Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">廖梦羽|软件工程研究生在读|机器学习|篮球爱好者</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://studentlmy.github.io/2019/07/25/聚类-学习笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LMY">
      <meta itemprop="description" content="定一个小目标 每周至少更新一篇">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mengyu Liao Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">聚类--学习笔记

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-25 22:05:54 / 修改时间：23:43:41" itemprop="dateCreated datePublished" datetime="2019-07-25T22:05:54+08:00">2019-07-25</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="聚类——学习笔记"><a href="#聚类——学习笔记" class="headerlink" title="聚类——学习笔记"></a><strong>聚类——学习笔记</strong></h1><p>​    这是一个关于聚类算法的学习笔记，在学习的过程中，参考学习了周志华老师的《机器学习》，李航老师的《统计学习方法》，邹博老师和唐宇迪老师的机器学习网课，以及网上的一些博客分享，其中<a href="https://www.cnblogs.com/pinard/p/6208966.html" target="_blank" rel="noopener">李建平先生的博客</a>中的分享和总结，给我提供了非常多的帮助。作为一个刚开始学习机器学习算法的学生，非常感谢网络上这些博主的总结和分享，也希望自己能够坚持下去，收获的同时给出自己的分享，做出一点点微薄的贡献。</p>
<h2 id="聚类的定义"><a href="#聚类的定义" class="headerlink" title="聚类的定义"></a><strong>聚类的定义</strong></h2><ul>
<li>聚类试图将数据集中样本划分成若干个通常是不相交的子集，每个子集称为一个“簇”（cluster）。使得聚类的结果“<strong>簇内相似度</strong>”高，并且“<strong>簇间相似度</strong>”低。</li>
<li>是无监督学习（没有标注）</li>
</ul>
<h2 id="聚类性能度量"><a href="#聚类性能度量" class="headerlink" title="聚类性能度量"></a>聚类性能度量</h2><ul>
<li>外部指标（external index）：将聚类结果于某个“参考模型”（例如领域专家给出的划分结果）比较</li>
<li>内部指标（internal index）：直接考察聚类结果，不利用任何“参考模型”</li>
</ul>
<h3 id="外部指标（external-index）"><a href="#外部指标（external-index）" class="headerlink" title="外部指标（external index）"></a>外部指标（external index）</h3><p>在周志华的《机器学习》中，给出如下定义：</p>
<p>​    对于数据集$D=\left\{\boldsymbol{x}_1,\boldsymbol{x}_2,\cdots,\boldsymbol{x}_m\right\}$,假定通过聚类给出的簇划分为$\boldsymbol{C}=\left\{C_1,C_2,\cdots,C_k\right\}$，对于参考模型给出的簇划分<script type="math/tex">\boldsymbol{C^*}=\left\{C_1^*,C_2^*,\cdots,C_s^*\right\}</script> </p>
<p>​        相应的，令 <script type="math/tex">\boldsymbol{\lambda}</script> 和<script type="math/tex">\boldsymbol{\lambda^*}</script> 分别表示与 <script type="math/tex">\boldsymbol{C}</script> 和 $ $\boldsymbol{C^*}$ $对应的簇标记向量，我们将样本两两配对考虑，定义：            </p>
<p>​                        <script type="math/tex">a=|SS|,SS=\left\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i=\lambda_J,\lambda_i^*=\lambda_J^*,i<j\right\},\\b=|SD|,SD=\left\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i=\lambda_J,\lambda_i^*\neq\lambda_J^*,i<j\right\},\\c=|DS|,DS=\left\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i\neq\lambda_J,\lambda_i^*=\lambda_J^*,i<j\right\},\\d=|DD|,DD=\left\{(\boldsymbol{x}_i,\boldsymbol{x}_j)|\lambda_i\neq\lambda_J,\lambda_i^*\neq\lambda_J^*,i<j\right\}</script>  </p>
<p>翻译这段定义，即</p>
<ul>
<li>a = 在C中属于相同簇,且在C*中也属于相同簇的样本对 （1,1）</li>
<li>b = 在C中属于相同簇,但在C*中属于不同簇的样本对 （1,0）</li>
<li>c = 在C中属于不同簇,但在C*中属于相同簇的样本对 （0,1）</li>
<li>d = 在C中属于不同簇,且在C*中也属于不同簇的样本对 （0,0）</li>
</ul>
<p>由于每个样本仅能出现在一个集合中，有</p>
<p>​                                     <script type="math/tex">a+b+c+d=m(m-1)/2</script></p>
<p>得到以下外部指标：</p>
<ul>
<li><p>Jaccard 系数：</p>
<script type="math/tex; mode=display">
JC = \frac{a}{a+b+c}</script></li>
<li><p>FM指数：</p>
<script type="math/tex; mode=display">
FMI = \sqrt{\frac{a}{a+b} \frac{a}{a+c}}</script></li>
<li><p>Rand指数：</p>
<script type="math/tex; mode=display">
RI = \frac{2(a+d)}{m(m-1)}</script></li>
</ul>
<p>举个例子说明：</p>
<p><img src="/2019/07/25/聚类-学习笔记/1563868681642.png" alt="1563868681642"></p>
<p>对于样本$D=\left\{X_1,X_2,X_3,X_4,X_5,X_6\right\}$,聚类簇和参考簇做出了如上图分类，则有</p>
<p>$a=|SS|=4,SS=\left\{(X_1,X_2),(X_4,X_5),(X_4,X_6),(X_5,X_6)\right\},$</p>
<p>$b=|SD|=2,SD=\left\{(X_1,X_3),(X_2,X_3)\right\},$</p>
<p>$c=|DS|=3,DS=\left\{(X_3,X_4),(X_3,X_5),(X_3,X_6)\right\},$</p>
<p>$d=|DD|=6,DD=\left\{(X_1,X_4),(X_1,X_5),(X_1,X_6),(X_2,X_4),(X_2,X_5),(X_2,X_6)\right\}$</p>
<p>则有 </p>
<ul>
<li><p>Jaccard 系数：</p>
<script type="math/tex; mode=display">
JC = \frac{a}{a+b+c}=\frac{4}{9}</script></li>
<li><p>FM指数：</p>
<script type="math/tex; mode=display">
FMI = \sqrt{\frac{a}{a+b} \frac{a}{a+c}}=\frac{4}{\sqrt{42}}</script></li>
<li><p>Rand指数：</p>
<script type="math/tex; mode=display">
RI = \frac{2(a+d)}{m(m-1)}=\frac{2}{3}</script></li>
</ul>
<p>上述性能度量的结果均在[0,1]之间，值越大越好</p>
<h3 id="内部指标（internal-index）"><a href="#内部指标（internal-index）" class="headerlink" title="内部指标（internal index）"></a>内部指标（internal index）</h3><p>​    考虑簇的划分结果$\mathcal{C} = {C_1,C_2,…, C_k}$,定义：</p>
<script type="math/tex; mode=display">
avg(C) = \frac{2}{|C|(|C|-1)} \sum_{1\leq i < j \leq |C|} dist(x_i, x_j)</script><script type="math/tex; mode=display">
diam(C) = max_{1\leq i < j \leq |C|} dist(x_i, x_j)</script><script type="math/tex; mode=display">
d_{min} (C_i, C_j) = min_{x_i\in C_i, x_j \in C_j} dist(x_i, x_j)</script><script type="math/tex; mode=display">
d_{cen} (C_i, C_j) = dist(\mu_i, \mu_j)</script><p>$\mu$是是$C$的中心点。$avg(C)$是簇$C$内样本平均距离，$diam(C)$是簇内样本间最远距离，$d_{min} (C_i, C_j)$是对应簇$C_i$，簇$C_j$的最近样本距离，$d_{cen}(C_i,C_j)$是簇中心距离。</p>
<p>基于上面的式子可以得到下面的内部指标：</p>
<ul>
<li><p>DB指数:</p>
<script type="math/tex; mode=display">
DBI＝　\frac{1}{k} \sum_{i=1}^k max_{j\neq i} (\frac{(avg(C_i)+avg(C_j)}{d_{cen}(\mu_i, \mu_j)})</script></li>
<li><p>Dunn指数：</p>
<script type="math/tex; mode=display">
DI = min_{1\leq i \leq k} \{ min_{j\neq i}(\frac{d_{min}(C_i,C_j)}{max_{1\leq l \leq k} diam(C_l)})</script></li>
</ul>
<p>举个例子：</p>
<p><img src="/2019/07/25/聚类-学习笔记/1563890382567.png" alt="1563890382567"></p>
<p>显然，DBI的值越小越好，DI的值越大越好</p>
<h2 id="相似度-similarity-距离-distance"><a href="#相似度-similarity-距离-distance" class="headerlink" title="相似度(similarity)/距离(distance)"></a>相似度(similarity)/距离(distance)</h2><h3 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h3><p>​       <strong>距离越大，相似度越小</strong></p>
<h4 id="闵科夫斯基距离"><a href="#闵科夫斯基距离" class="headerlink" title="闵科夫斯基距离"></a>闵科夫斯基距离</h4><p>​    其中，$，x_i,x_j\in X,x_i=(x_{1i},x_{2i},\cdots,x_{mi})^T,x_j=(x_{1j},x_{2j},\cdots,x_{mj})^T,p\geq1$</p>
<script type="math/tex; mode=display">
d(x_i,x_j)=\left(\sum_{k=1}^{m}|x_{ki}-x_{kj}|^p\right)^{\frac{1}{p}}</script><h4 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h4><p>​    当$p=2$时，即</p>
<script type="math/tex; mode=display">
d(x_i,x_j)=\left(\sum_{k=1}^{m}|x_{ki}-x_{kj}|^2\right)^{\frac{1}{2}}</script><h4 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h4><p>​    当$p=1$时，即</p>
<script type="math/tex; mode=display">
d(x_i,x_j)=\sum_{k=1}^{m}|x_{ki}-x_{kj}|</script><h4 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h4><p>​    当$p=\infty$时，取各个坐标数值差的绝对值的最大值，即  </p>
<script type="math/tex; mode=display">
d(x_i,x_j)=\mathop{\max}\limits_k|x_{ki}-x_{kj}|</script><h4 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h4><p><img src="/2019/07/25/聚类-学习笔记/1563863833861.png" alt="1563863833861"></p>
<p>对于上图$X_1,X_2$两点，则有：</p>
<ol>
<li>欧式距离：当$p=2$时，距离$d=a$</li>
<li>曼哈顿距离：当$p=1$时，距离$d=b+c$</li>
<li>切比雪夫距离：当$p=\infty$时,距离$d=Max(b,c)$</li>
</ol>
<h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><ul>
<li>有序属性：{1，2，3}  —————用闵科夫斯基距离</li>
<li>无序属性：{飞机，火车，轮船}—————用VDM（Value Difference Metric）</li>
</ul>
<p>VDM看得我头皮发麻，以后再看，（西瓜书上有）</p>
<h3 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h3><h4 id="Pearson相似度"><a href="#Pearson相似度" class="headerlink" title="Pearson相似度"></a>Pearson相似度</h4><p><img src="/2019/07/25/聚类-学习笔记/1563870386014.png" alt="1563870386014"></p>
<h4 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h4><p><img src="/2019/07/25/聚类-学习笔记/1563870438048.png" alt="1563870438048"></p>
<p><strong>相关系数越大，样本越相似</strong></p>
<p>注意：不同的相似度度量得到的结果并不相同</p>
<h4 id="拓展-1"><a href="#拓展-1" class="headerlink" title="拓展"></a>拓展<img src="/2019/07/25/聚类-学习笔记/1563870492326.png" alt="1563870492326"></h4><p><img src="/2019/07/25/聚类-学习笔记/1563870532597.png" alt="1563870532597"></p>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><h3 id="聚类的基本思想"><a href="#聚类的基本思想" class="headerlink" title="聚类的基本思想"></a>聚类的基本思想</h3><p>​    给定一个有$N$个对象的数据集，构造数据的k个簇，$K\leq N$。满足下列条件：</p>
<ul>
<li>每一个簇至少包含一个对象</li>
<li>每一个对象属于且仅属于一个簇</li>
</ul>
<h3 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h3><p>基于原型的的聚类，假设聚类结构能够通过一组<strong>原型</strong>刻画。通常情况下，算法先对原型进行初始化，对原型进行迭代更新求解，采用不同的原型表示，不同的求解方式，将产生不同的算法。</p>
<h4 id="K-means算法（k-均值）："><a href="#K-means算法（k-均值）：" class="headerlink" title="K-means算法（k-均值）："></a>K-means算法（k-均值）：</h4><p><strong>基本思想</strong>：对于给定的样本集，按照样本之间的距离大小，将样本集划分为K个簇。让<strong>簇内的点尽量紧密的连在一起</strong>，而让<strong>簇间的距离尽量的大</strong>。</p>
<p>​    如果用数据表达式表示，假设簇划分为$(C_1,C_2,…C_k)$，则我们的目标是最小化平方误差$E$：</p>
<script type="math/tex; mode=display">
E = \sum\limits_{i=1}^k\sum\limits_{x \in C_i} ||x-\mu_i||_2^2</script><p>​    其中$\mu_i$是簇$C_i$的均值向量，有时也称为质心，表达式为：</p>
<script type="math/tex; mode=display">
\mu_i = \frac{1}{|C_i|}\sum\limits_{x \in C_i}x</script><p>如果我们想直接求$E$的最小值并不容易，找到他的最优解需要参考样本集$D$所有了可能的簇划分，这是一个NP难的问题，因此，k均值算法才采用贪心策略，通过迭代优化近似求解E。</p>
<p><strong>基本流程：</strong></p>
<p><img src="/2019/07/25/聚类-学习笔记/1564066135661.png" alt="1564066135661"></p>
<p><strong>算法步骤：</strong>　</p>
<p>输入是样本集$D=\{x_1,x_2,…x_m\}$聚类的簇树k,最大迭代次数N。</p>
<ol>
<li><p>从数据集D中随机选择k个样本作为初始的K个类别的质心向量：$\{\mu_1,\mu_2,…,\mu_k\}$</p>
</li>
<li><p>对于每个样本$x_i$,将其标记为距离类别质心最近的类别，即：</p>
<script type="math/tex; mode=display">
lable_i=arg\mathop{\min}\limits_{1\leq j\leq k}||x_{i} - \mu_j||</script></li>
<li><p>更新每个类别的质心为该类别中所有样本的均值：</p>
<script type="math/tex; mode=display">
\mu_j = \frac{1}{|C_j|}\sum\limits_{x \in C_j}x_i</script></li>
<li><p>重复2，3步，直到中心类别的变化小于某个阈值。</p>
</li>
</ol>
<p><strong>终止条件：</strong></p>
<p>​    迭代次数 <strong>/</strong> 簇中心变化率 <strong>/ </strong>最小平方误差MSE</p>
<h4 id="K-means的过程"><a href="#K-means的过程" class="headerlink" title="K-means的过程"></a>K-means的过程</h4><p>过程图示：</p>
<p><img src="/2019/07/25/聚类-学习笔记/1563957206834.png" alt="1563957206834"></p>
<h4 id="k-means总结"><a href="#k-means总结" class="headerlink" title="k-means总结"></a>k-means总结</h4><p>​    优点：快速，简单，适合常规数据，聚类效果较好，只需要调一个参K</p>
<p>​    缺点：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">问题</th>
<th style="text-align:left">解决</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">K值难以确定</td>
<td style="text-align:left">根据对数据的先验经验选择一个K值<br>通过交叉验证选择合适的K值</td>
</tr>
<tr>
<td style="text-align:center">对异常值和噪音敏感，异常值会导致均值严重偏离</td>
<td style="text-align:left">将取均值改为取中位数</td>
</tr>
<tr>
<td style="text-align:center">难发现任意形状的聚类</td>
<td style="text-align:left">密度聚类 DBSCAN算法</td>
</tr>
<tr>
<td style="text-align:center">对质心的初始位置敏感</td>
<td style="text-align:left">k-means的初始化优化K-means++算法</td>
</tr>
<tr>
<td style="text-align:center">复杂度与样本呈线性关系</td>
<td style="text-align:left">大样本优化Mini Batch K-means</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2019/07/25/聚类-学习笔记/1563970072445.png" alt="1563970072445"></p>
<p><img src="/2019/07/25/聚类-学习笔记/1563970670788.png" alt="1563970670788"></p>
<p>算法可视化展示：<a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/" target="_blank" rel="noopener">这是一个在线的k-means算法可视化展示网站</a></p>
<h4 id="K-means-算法"><a href="#K-means-算法" class="headerlink" title="K-means++算法"></a>K-means++算法</h4><p>​    由于k个初始化的质心的位置选择对最后的聚类结果和运行时间都有很大的影响，因此需要选择合适的k个质心。如果仅仅是完全随机的选择，有可能导致算法收敛很慢。K-Means++算法就是对K-Means随机初始化质心的方法的优化。</p>
<p>K-Means++的对于初始化质心的优化策略也很简单，如下：</p>
<p>　　a)  从输入的数据点集合中随机选择一个点作为第一个聚类中心$\mu_1$<br>　　b) 对于数据集中的每一个点$x_i$，计算它与已选择的聚类中心中最近聚类中心的距离$D(x_i) = arg\;min||x_i- \mu_r||_2^2\;\;r=1,2,…k_{selected}$</p>
<p>　　c) 选择一个新的数据点作为新的聚类中心，选择的原则是：$D(x)$较大的点，被选取作为聚类中心的概率较大<br>　　d) 重复b和c直到选择$K$个聚类质心<br>　　e) 利用这$K$个质心来作为初始化质心去运行标准的K-Means算法</p>
<p><img src="/2019/07/25/聚类-学习笔记/1563972609072.png" alt="1563972609072"></p>
<h4 id="Mini-Batch-K-Means算法"><a href="#Mini-Batch-K-Means算法" class="headerlink" title="Mini Batch K-Means算法"></a>Mini Batch K-Means算法</h4><p>​    scikit-learn官网上对于Mini Batch K-Means算法的说明如下：</p>
<p>​    Mini Batch K-Means算法是K-Means算法的变种，采用小批量的数据子集减小计算时间，同时仍试图优化目标函数，这里所谓的小批量是指每次训练算法时所随机抽取的数据子集，采用这些随机产生的子集进行训练算法，大大减小了计算时间，与其他算法相比，减少了k-均值的收敛时间，小批量k-均值产生的结果，一般只略差于标准算法。</p>
<p>​    该算法的迭代步骤有两步：</p>
<p>1：从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心</p>
<p>2：更新质心</p>
<p>​    与K均值算法相比，数据的更新是在每一个小的样本集上。对于每一个小批量，通过计算平均值得到更新质心，并把小批量里的数据分配给该质心，随着迭代次数的增加，这些质心的变化是逐渐减小的，直到质心稳定或者达到指定的迭代次数，停止计算</p>
<p>​    Mini Batch K-Means比K-Means有更快的收敛速度，但同时也降低了聚类的效果，但是在实际项目中却表现得不明显</p>
<p>​                                      <strong>这是一张k-means和mini batch k-means的实际效果对比图</strong></p>
<p><img src="https://img-blog.csdn.net/20160426002823787?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<h3 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h3><ol>
<li>样本点的密度大于某个阈值，则将该样本点添加到最近的簇中</li>
<li>可以克服基于距离的聚类算法只能发现“类圆形”的聚类的缺点，可以发现任何形状的聚类，且对噪声不敏感。</li>
</ol>
<h4 id="DBSCAN算法"><a href="#DBSCAN算法" class="headerlink" title="DBSCAN算法"></a>DBSCAN算法</h4><ul>
<li><p><strong>$\epsilon$-邻域</strong>：对于$x_j \in D$其$\epsilon$-邻域包含样本集D中与$x_j$的距离不大于$\epsilon$的子样本集，即$N_{\epsilon}(x_j) = \{x_i \in D | distance(x_i,x_j) \leq \epsilon\}$, 这个子样本集的个数记为$|N_{\epsilon}(x_j)|$</p>
</li>
<li><p><strong>核心对象</strong>:对于任一样本$x_j \in D$，如果其$\epsilon$-邻域对应的$N_{\epsilon}(x_j)$至少包含MinPts个样本，即如果$|N_{\epsilon}(x_j)| \geq MinPts$，则$x_j$ 是核心对象。　</p>
</li>
<li><p><strong>密度直达（直接密度可达）:</strong></p>
<p>​        如果$x_i$位于$x_j$ 的$\epsilon$-邻域中，且$x_j$ 是核心对象，则称$x_i$i由$x_j$ 密度直达。注意反之不一定成立，即此时不能说$x_j$ 由$x_i$密度直达, 除非且$x_i$也是核心对象</p>
</li>
<li><p><strong>密度可达:</strong></p>
<p>​        对于$x_i$i和$x_j$ ,如果存在样本样本序列$p_1, p_2,…,p_T$,满足$p_1 = x_i, p_T = x_j$, 且$p_{t+1}$由$p_t$密度直达，则称$x_j$由$x_i$ 密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本$p_1, p_2,…,p_{T-1}$均为核心对象，因为只有核心对象才能使其他样本密度直达。注意密度可达也不满足对称性，这个可以由密度直达的不对称性得出。</p>
</li>
<li><p><strong>密度相连:</strong>对于$x_i$和$x_j$ ,如果存在核心对象样本$x_k$，使$x_i$和$x_j$ 均由$x_k$ 密度可达，则称$x_i$和$x_j$ 密度相连。注意密度相连关系是满足对称性的</p>
</li>
</ul>
<p><strong>例1：</strong></p>
<p><img src="/2019/07/25/聚类-学习笔记/1563884860873.png" alt="1563884860873"></p>
<p>​            图中MinPts=5，红色的点都是核心对象，因为其ϵϵ-邻域至少有5个样本。黑色的样本是非核心对象。所有核心对象密度直达的样本在以红色核心对象为中心的超球体内，如果不在超球体内，则不能密度直达。图中用绿色箭头连起来的核心对象组成了密度可达的样本序列。在这些密度可达的样本序列的ϵϵ-邻域内所有的样本相互都是密度相连的</p>
<p><strong>例2：</strong></p>
<p><img src="/2019/07/25/聚类-学习笔记/1563885220041.png" alt="1563885220041"></p>
<ul>
<li>DBSCAN算法的“簇”：一个基于密度的簇是最大的密度相连的对象的集合</li>
<li>噪声：不包含在任何簇中的对象称为噪声</li>
</ul>
<h4 id="DBSCAN算法流程"><a href="#DBSCAN算法流程" class="headerlink" title="DBSCAN算法流程"></a>DBSCAN算法流程</h4><p>输入：样本集$D=(x_1,x_2,…,x_m)$，邻域参数$(\epsilon, MinPts)$, 样本距离度量方式</p>
<p>　　输出： 簇划分C.　</p>
<p>　　1）初始化核心对象集合$\Omega = \emptyset$, 初始化聚类簇数k=0，初始化未访问样本集合$\Gamma$= D,  簇划分C = $\emptyset$</p>
<p>　　2) 对于j=1,2,…m, 按下面的步骤找出所有的核心对象：</p>
<p>​    　　a) 通过距离度量方式，找到样本$x_i$的$\epsilon-$邻域子样本集$N_{\epsilon}(x_j)$</p>
<p>　　　b) 如果子样本集样本个数满足$|N_{\epsilon}(x_j)| \geq MinPts$， 将样本$x_j$j加入核心对象样本集合：$\Omega = \Omega \cup \{x_j\}$</p>
<p>​    　3）如果核心对象集合$\Omega = \emptyset$，则算法结束，否则转入步骤4.</p>
<p>　    4）在核心对象集合$\Omega$中，随机选择一个核心对象$o$，初始化当前簇核心对象队列$\Omega_{cur} = \{o\}$, 初始化类别序号k=k+1，初始化当前簇样本集合$C_k =  \{o\}$, 更新未访问样本集合$\Gamma = \Gamma -  \{o\}$</p>
<p>　　5）如果当前簇核心对象队列$\Omega_{cur} = \emptyset$，则当前聚类簇$C_k$生成完毕, 更新簇划分$C=\{C_1,C_2,…,C_k\}$, 更新核心对象集合$\Omega = \Omega - {C_k}$， 转入步骤3。</p>
<p>　　6）在当前簇核心对象队列$\Omega_{cur}$中取出一个核心对象$o^{‘}$,通过邻域距离阈值$\epsilon$找出所有的$\epsilon$-邻域子样本集$N_{\epsilon}(o^{‘})$，令$\Delta = N_{\epsilon}(o^{‘}) \cap \Gamma$, 更新当前簇样本集合$C_k =C_k \cup \Delta$, 更新未访问样本集合$\Gamma = \Gamma - \Delta$,  更新$\Omega_{cur} = \Omega_{cur} \cup (\Delta \cap \Omega) - {o’}$，转入步骤5.</p>
<p>　　　　输出结果为： 簇划分$C=\{C_1,C_2,…,C_k\}$</p>
<p>算法可视化展示：<a href="https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/" target="_blank" rel="noopener">这是一个DBSCAN算法的在线可视化展示网站</a></p>
<h4 id="CDBSCAN总结"><a href="#CDBSCAN总结" class="headerlink" title="CDBSCAN总结"></a>CDBSCAN总结</h4><p>​    优点：</p>
<p>​            1.可以发现任意形状的聚类。</p>
<p>​            2.对异常值不敏感，聚类的同时可以发现异常点。</p>
<p>​            3.没有k-means算法那种初始值对聚类结果的影响</p>
<p>​     缺点：</p>
<p>​             1.如果样本集较大时，聚类收敛时间较长,此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改                        进。(还没了解过)</p>
<p>​             2.调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值ϵϵ，邻域样本数阈值MinPts联                合调参，不同的参数组合对最后的聚类效果有较大影响。</p>
<p>​        　3. 如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合</p>
<h3 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h3><ul>
<li>凝聚的层次聚类：AGNES算法</li>
<li>分裂的层次聚类：DIANA算法</li>
</ul>
<p>AGNES算法：自底向上策略，首先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到某个终结条件</p>
<p>DIANA算法：自顶部向下策略，首先将所有对象置于同一个簇，然后逐渐细分为越来越小的簇，直到某个终结条件</p>
<p><img src="/2019/07/25/聚类-学习笔记/1563882318053.png" alt="1563882318053"></p>

      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/聚类/" rel="tag"># 聚类</a>
          
            <a href="/tags/算法/" rel="tag"># 算法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/15/testtest/" rel="next" title="我的第一篇blog测试">
                <i class="fa fa-chevron-left"></i> 我的第一篇blog测试
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="LMY">
  
  <p class="site-author-name" itemprop="name">LMY</p>
  <div class="site-description motion-element" itemprop="description">定一个小目标 每周至少更新一篇</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-categories">
        
        
        
          
        
          
        
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span>
        
      </div>
    

    
      
      
      <div class="site-state-item site-state-tags">
        
        
        
          
        
          
        
          
        
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
        
      </div>
    
  </nav>













          
          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#聚类——学习笔记"><span class="nav-number">1.</span> <span class="nav-text">聚类——学习笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类的定义"><span class="nav-number">1.1.</span> <span class="nav-text">聚类的定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类性能度量"><span class="nav-number">1.2.</span> <span class="nav-text">聚类性能度量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#外部指标（external-index）"><span class="nav-number">1.2.1.</span> <span class="nav-text">外部指标（external index）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内部指标（internal-index）"><span class="nav-number">1.2.2.</span> <span class="nav-text">内部指标（internal index）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相似度-similarity-距离-distance"><span class="nav-number">1.3.</span> <span class="nav-text">相似度(similarity)/距离(distance)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#距离计算"><span class="nav-number">1.3.1.</span> <span class="nav-text">距离计算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#闵科夫斯基距离"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">闵科夫斯基距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#欧式距离"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">欧式距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#曼哈顿距离"><span class="nav-number">1.3.1.3.</span> <span class="nav-text">曼哈顿距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切比雪夫距离"><span class="nav-number">1.3.1.4.</span> <span class="nav-text">切比雪夫距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#举例"><span class="nav-number">1.3.1.5.</span> <span class="nav-text">举例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拓展"><span class="nav-number">1.3.1.6.</span> <span class="nav-text">拓展</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关系数"><span class="nav-number">1.3.2.</span> <span class="nav-text">相关系数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Pearson相似度"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">Pearson相似度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#余弦相似度"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">余弦相似度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拓展-1"><span class="nav-number">1.3.2.3.</span> <span class="nav-text">拓展</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类"><span class="nav-number">1.4.</span> <span class="nav-text">聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#聚类的基本思想"><span class="nav-number">1.4.1.</span> <span class="nav-text">聚类的基本思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原型聚类"><span class="nav-number">1.4.2.</span> <span class="nav-text">原型聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#K-means算法（k-均值）："><span class="nav-number">1.4.2.1.</span> <span class="nav-text">K-means算法（k-均值）：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-means的过程"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">K-means的过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#k-means总结"><span class="nav-number">1.4.2.3.</span> <span class="nav-text">k-means总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-means-算法"><span class="nav-number">1.4.2.4.</span> <span class="nav-text">K-means++算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mini-Batch-K-Means算法"><span class="nav-number">1.4.2.5.</span> <span class="nav-text">Mini Batch K-Means算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#密度聚类"><span class="nav-number">1.4.3.</span> <span class="nav-text">密度聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DBSCAN算法"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">DBSCAN算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DBSCAN算法流程"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">DBSCAN算法流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CDBSCAN总结"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">CDBSCAN总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#层次聚类"><span class="nav-number">1.4.4.</span> <span class="nav-text">层次聚类</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LMY</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  













  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  

  


  


  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  


  

</body>
</html>
